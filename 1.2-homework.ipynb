{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laplace618/BJTU-AIS/blob/main/1.2-homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to use this starter kit\n",
        "\n",
        "1. **Copy the notebook**. This is a shared file so your changes will not be saved. Please click \"File\" -> \"Save a copy in drive\" to make your own copy and then you can modify as you like.\n",
        "\n",
        "2. **Implement your own method**. Please put all your code into the `clean_model` function in section 4."
      ],
      "metadata": {
        "id": "J0KS3EMB9OFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Download and import package"
      ],
      "metadata": {
        "id": "WkI4fII__74u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M_fk-Vay8Cdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbf0289-0fb0-45c8-a72f-e46c9dc9171d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 timm-0.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting func_timeout\n",
            "  Downloading func_timeout-4.3.5.tar.gz (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: func_timeout\n",
            "  Building wheel for func_timeout (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for func_timeout: filename=func_timeout-4.3.5-py3-none-any.whl size=15079 sha256=853d2ca6322d35521d019a260d72c4c954b39119de70e4f2b9b2cb4bdbd469cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/83/19/b5552bb9630e353f7c5b15be44bf10900afe1abbbfcf536afd\n",
            "Successfully built func_timeout\n",
            "Installing collected packages: func_timeout\n",
            "Successfully installed func_timeout-4.3.5\n"
          ]
        }
      ],
      "source": [
        "#@title Load package and data\n",
        "\n",
        "# !pip install torch==1.13.1\n",
        "!pip install timm\n",
        "!pip install func_timeout\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, Subset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import functional as F\n",
        "import torchvision\n",
        "import os\n",
        "import random\n",
        "import tqdm\n",
        "from torchvision import transforms\n",
        "import copy\n",
        "import time\n",
        "from tqdm.notebook import trange, tqdm\n",
        "torch.cuda.empty_cache()\n",
        "device = 'cuda'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download dataset and models\n",
        "%%shell\n",
        "\n",
        "filename='competition_data.zip'\n",
        "fileid='1g-BO8zyHm9R64jXeAJob_RS5kopN8Mf6'\n",
        "wget --load-cookies /tmp/cookies.txt \"https://drive.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=${fileid}' -O- | sed -rn 's/.confirm=([0-9A-Za-z_]+)./\\1\\n/p')&id=${fileid}\" -O ${filename} && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "id": "7Wk7bNxj_TcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c581871-c35f-4c5a-f0de-6d4d6bbaa7ba",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-07 06:06:41--  https://drive.google.com/uc?export=download&confirm=&id=1g-BO8zyHm9R64jXeAJob_RS5kopN8Mf6\n",
            "Resolving drive.google.com (drive.google.com)... 142.250.97.102, 142.250.97.138, 142.250.97.113, ...\n",
            "Connecting to drive.google.com (drive.google.com)|142.250.97.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-00-0k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2tjuef5f9qdvdvpdnpar8khfcahv26eo/1686117975000/05487030300566610993/*/1g-BO8zyHm9R64jXeAJob_RS5kopN8Mf6?e=download&uuid=3a9ab4aa-a72e-414a-87c5-e3a449f07652 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-06-07 06:06:41--  https://doc-00-0k-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/2tjuef5f9qdvdvpdnpar8khfcahv26eo/1686117975000/05487030300566610993/*/1g-BO8zyHm9R64jXeAJob_RS5kopN8Mf6?e=download&uuid=3a9ab4aa-a72e-414a-87c5-e3a449f07652\n",
            "Resolving doc-00-0k-docs.googleusercontent.com (doc-00-0k-docs.googleusercontent.com)... 172.217.204.132, 2607:f8b0:400c:c15::84\n",
            "Connecting to doc-00-0k-docs.googleusercontent.com (doc-00-0k-docs.googleusercontent.com)|172.217.204.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1074003019 (1.0G) [application/x-zip-compressed]\n",
            "Saving to: ‘competition_data.zip’\n",
            "\n",
            "competition_data.zi 100%[===================>]   1.00G   129MB/s    in 12s     \n",
            "\n",
            "2023-06-07 06:06:53 (87.6 MB/s) - ‘competition_data.zip’ saved [1074003019/1074003019]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Unzip the package\n",
        "!unzip './competition_data.zip' -d '/content'\n",
        "from util import *\n",
        "import timm\n",
        "from func_timeout import func_timeout,FunctionTimedOut"
      ],
      "metadata": {
        "id": "8lOMzdZv8Nv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6d57756-e19a-46fb-cc6c-1f502fd47b44",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./competition_data.zip\n",
            "   creating: /content/checkpoint/\n",
            "  inflating: /content/checkpoint/cifar10_resnet18_sig.pth  \n",
            "  inflating: /content/checkpoint/gtsrb_googlenet_wantfrequency.pth  \n",
            "  inflating: /content/checkpoint/gtsrb_universal.npy  \n",
            "  inflating: /content/checkpoint/narcissus_trigger.npy  \n",
            "  inflating: /content/checkpoint/pubfig_vittiny_all2all.pth  \n",
            "  inflating: /content/checkpoint/stl_10_vgg.pth  \n",
            "  inflating: /content/checkpoint/tiny_imagenet_resnet18_narcissus.pth  \n",
            "  inflating: /content/checkpoint/WaNet_identity_grid.pth  \n",
            "  inflating: /content/checkpoint/WaNet_noise_grid.pth  \n",
            "   creating: /content/data/\n",
            "  inflating: /content/data/cifar_10.npy  \n",
            "  inflating: /content/data/gtsrb.npy  \n",
            "  inflating: /content/data/pubfig.npy  \n",
            "  inflating: /content/data/stl10.npy  \n",
            "  inflating: /content/data/tiny_imagenet.npy  \n",
            "  inflating: /content/util.py        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IOycqlem8Cdd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load all poisoned models and evaluation datasets\n",
        "## BadNets all2all\n",
        "def PubFig_all2all():\n",
        "  def all2all_badnets(img):\n",
        "    img[184:216,184:216,:] = 255\n",
        "    return img\n",
        "      \n",
        "  def all2all_label(label):\n",
        "    if label == 83:\n",
        "      return int(0)\n",
        "    else:\n",
        "      return int(label + 1)\n",
        "\n",
        "  test_transform = transforms.Compose([\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])\n",
        "\n",
        "  poison_method = ((all2all_badnets, None), all2all_label)\n",
        "  val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/pubfig.npy', test_transform, poison_method, -1)\n",
        "\n",
        "\n",
        "  net = timm.create_model(\"vit_tiny_patch16_224\", pretrained=False, num_classes=83)\n",
        "  net.load_state_dict(torch.load('./checkpoint/pubfig_vittiny_all2all.pth',map_location='cuda:0'))\n",
        "  net = net.cuda()\n",
        "\n",
        "  return val_dataset, test_dataset, asr_dataset, pacc_dataset, net\n",
        "\n",
        "## SIG\n",
        "def CIFAR10_SIG():\n",
        "    best_noise = np.zeros((32, 32, 3))\n",
        "    def plant_sin_trigger(img, delta=20, f=6, debug=False):\n",
        "        \"\"\"\n",
        "        Implement paper:\n",
        "        > Barni, M., Kallas, K., & Tondi, B. (2019).\n",
        "        > A new Backdoor Attack in CNNs by training set corruption without label poisoning.\n",
        "        > arXiv preprint arXiv:1902.11237\n",
        "        superimposed sinusoidal backdoor signal with default parameters\n",
        "        \"\"\"\n",
        "        alpha = 0.2\n",
        "        pattern = np.zeros_like(img)\n",
        "        m = pattern.shape[1]\n",
        "        for i in range(img.shape[0]):\n",
        "            for j in range(img.shape[1]):\n",
        "                for k in range(img.shape[2]):\n",
        "                    pattern[i, j] = delta * np.sin(2 * np.pi * j * f / m)\n",
        "\n",
        "        return np.uint8((1 - alpha) * pattern)\n",
        "    noisy = plant_sin_trigger(best_noise, delta=20, f=15, debug=False)\n",
        "\n",
        "    def SIG(img):\n",
        "        return img + noisy\n",
        "\n",
        "    def SIG_tar(label):\n",
        "        return 6\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    poison_method = ((SIG, None), SIG_tar)\n",
        "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/cifar_10.npy', test_transform, poison_method, 6)\n",
        "\n",
        "    net = ResNet18().cuda()\n",
        "    net.load_state_dict(torch.load('./checkpoint/cifar10_resnet18_sig.pth',map_location='cuda:0'))\n",
        "    net = net.cuda()\n",
        "\n",
        "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net\n",
        "\n",
        "## Narcissus\n",
        "def TinyImangeNet_Narcissus():\n",
        "    noisy = np.load('./checkpoint/narcissus_trigger.npy')[0]\n",
        "    def Narcissus(img):\n",
        "        return torch.clip(img + noisy*3,-1,1)\n",
        "\n",
        "    def Narcissus_tar(label):\n",
        "        return 2\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    poison_method = ((None, Narcissus), Narcissus_tar)\n",
        "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/tiny_imagenet.npy', test_transform, poison_method, 2)\n",
        "\n",
        "    net = torchvision.models.resnet18()\n",
        "    num_ftrs = net.fc.in_features\n",
        "    net.fc = nn.Linear(num_ftrs, 200)\n",
        "    net.load_state_dict(torch.load('./checkpoint/tiny_imagenet_resnet18_narcissus.pth',map_location='cuda:0'))\n",
        "    net = net.cuda()\n",
        "\n",
        "    return val_dataset, test_dataset, asr_dataset, pacc_dataset, net\n",
        "\n",
        "def GTSRB_WaNetFrequency():\n",
        "    ## WaNet 1\n",
        "    identity_grid = copy.deepcopy(torch.load(\"./checkpoint/WaNet_identity_grid.pth\"))\n",
        "    noise_grid = copy.deepcopy(torch.load(\"./checkpoint/WaNet_noise_grid.pth\"))\n",
        "    h = identity_grid.shape[2]\n",
        "    s = 0.5\n",
        "    grid_rescale = 1\n",
        "    grid = identity_grid + s * noise_grid / h\n",
        "    grid = torch.clamp(grid * grid_rescale, -1, 1)\n",
        "    noise_rescale = 2\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    def Wanet(img):\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1)\n",
        "        img = torchvision.transforms.functional.convert_image_dtype(img, torch.float)\n",
        "        poison_img = nn.functional.grid_sample(img.unsqueeze(0), grid, align_corners=True).squeeze()  # CHW\n",
        "        img = poison_img.permute(1, 2, 0).numpy()\n",
        "        # img = test_transform(img)\n",
        "        return img\n",
        "\n",
        "    def Wanet_tar(label):\n",
        "        return 2\n",
        "\n",
        "\n",
        "    poison_method = ((Wanet, None), Wanet_tar)\n",
        "    val_dataset, test_dataset, asr_dataset, pacc_dataset = get_dataset('./data/gtsrb.npy', test_transform, poison_method, 2)\n",
        "\n",
        "    net = GoogLeNet()\n",
        "    net.load_state_dict(torch.load('./checkpoint/gtsrb_googlenet_wantfrequency.pth',map_location='cuda:0'))\n",
        "    net = net.cuda()\n",
        "\n",
        "    ## Frequency 2\n",
        "    trigger_transform = transforms.Compose([transforms.ToTensor(),])\n",
        "    noisy = trigger_transform(np.load('./checkpoint/gtsrb_universal.npy')[0])\n",
        "    def Frequency(img):\n",
        "        return torch.clip(img + noisy,-1,1)\n",
        "\n",
        "    def Frequency_tar(label):\n",
        "        return 13\n",
        "\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    poison_method = ((None, Frequency), Frequency_tar)\n",
        "    _, _, asr_dataset2, pacc_dataset2 = get_dataset('./data/gtsrb.npy', test_transform, poison_method, 13)\n",
        "    \n",
        "    return val_dataset, test_dataset, (asr_dataset, asr_dataset2), (pacc_dataset, pacc_dataset2), net\n",
        "\n",
        "## Clean STL-10\n",
        "def STL10_Clean():\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(224),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "\n",
        "    poison_method = (None, None)\n",
        "    val_dataset, test_dataset, _, _ = get_dataset('./data/stl10.npy', test_transform, poison_method, -1)\n",
        "\n",
        "    net = torchvision.models.vgg16_bn()\n",
        "    net.load_state_dict(torch.load('./checkpoint/stl_10_vgg.pth',map_location='cuda:0'))\n",
        "    net = net.cuda()\n",
        "    \n",
        "    return val_dataset, test_dataset, None, None, net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pz9FGtJ8Cdf"
      },
      "source": [
        "# 2. Test attack effect\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Attack setting\n",
        "\n",
        "\n",
        "|               |        Case 1        |       Case 2       |         Case 3        |       Case 4       |        Case 5        |\n",
        "|:-------------:|:--------------------:|:------------------:|:---------------------:|:------------------:|:--------------------:|\n",
        "|     Model     |       VIT-Tiny       |      ResNet-18     |       ResNet-18       |      GoogLenet     |       VGG16-bn       |\n",
        "|    Dataset    |        PubFig        |      CIFAR-10      |     Tiny-ImageNet     |        GTSRB       |        STL-10        |\n",
        "|  Dataset Info | 224\\*224\\*3 83 Classes | 32\\*32\\*3 10 Classes | 224\\*224\\*3 200 Classes | 32\\*32\\*3 43 Classes | 224\\*224\\*3 10 Classes |\n",
        "| Poison Method |    BadNets All2All   |         SIG        |       Narcissus       |  WaNet & Frequency |          N/A         |\n",
        "|  Target Label |          All         |          6         |           2           |       2 & 13       |          N/A         |\n",
        "|  Defense Time |        1350 S        |        900 S       |         1800 S        |        690 S       |         450 S        |"
      ],
      "metadata": {
        "id": "J1LR4re84sNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title testing attack\n",
        "## Test Case-1\n",
        "print(\"----------------- Testing attack: PubFig all2all -----------------\")\n",
        "_, test_dataset, asr_dataset, pacc_dataset, model = PubFig_all2all()\n",
        "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
        "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
        "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
        "## Test Case-2\n",
        "print(\"----------------- Testing attack: CIFAR-10 SIG -----------------\")\n",
        "_, test_dataset, asr_dataset, pacc_dataset, model = CIFAR10_SIG()\n",
        "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
        "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
        "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
        "## Test Case-3\n",
        "print(\"----------------- Testing attack: Tiny-Imagenet Narcissus -----------------\")\n",
        "_, test_dataset, asr_dataset, pacc_dataset, model = TinyImangeNet_Narcissus()\n",
        "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
        "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
        "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
        "## Test Case-4\n",
        "print(\"----------------- Testing attack: GTSRB WaNet & Smooth -----------------\")\n",
        "_, test_dataset, asr_dataset, pacc_dataset, model = GTSRB_WaNetFrequency()\n",
        "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
        "print('WaNet ASR %.3f%%' % (100 * get_results(model, asr_dataset[0])))\n",
        "print('WaNet PACC %.3f%%' % (100 * get_results(model, pacc_dataset[0])))\n",
        "print('Smooth ASR %.3f%%' % (100 * get_results(model, asr_dataset[1])))\n",
        "print('Smooth PACC %.3f%%' % (100 * get_results(model, pacc_dataset[1])))\n",
        "## Test Case-5\n",
        "print(\"----------------- Testing attack: STL-10 -----------------\")\n",
        "_, test_dataset, _, _, model = STL10_Clean()\n",
        "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))"
      ],
      "metadata": {
        "id": "00Ts2YrN8m15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19fbc0b-d691-496e-9804-fccf3fd3d643",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Testing attack: PubFig all2all -----------------\n",
            "ACC：86.022%\n",
            "ASR 78.430%\n",
            "PACC 1.035%\n",
            "----------------- Testing attack: CIFAR-10 SIG -----------------\n",
            "ACC：93.822%\n",
            "ASR 95.617%\n",
            "PACC 3.716%\n",
            "----------------- Testing attack: Tiny-Imagenet Narcissus -----------------\n",
            "ACC：57.700%\n",
            "ASR 70.264%\n",
            "PACC 0.955%\n",
            "----------------- Testing attack: GTSRB WaNet & Smooth -----------------\n",
            "ACC：97.919%\n",
            "WaNet ASR 66.400%\n",
            "WaNet PACC 32.853%\n",
            "Smooth ASR 97.785%\n",
            "Smooth PACC 2.181%\n",
            "----------------- Testing attack: STL-10 -----------------\n",
            "ACC：100.000%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV_oFkq28Cdg"
      },
      "source": [
        "# 3. Baseline defense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "11y75jK98Cdg"
      },
      "outputs": [],
      "source": [
        "#@title test_defense\n",
        "def test_defense(defense_method):\n",
        "    models = []\n",
        "    ## Test Pubfig all2all\n",
        "    # print(\"----------------- Testing defense: PubFig all2all -----------------\")\n",
        "    # val_dataset, _, _, _, model = PubFig_all2all()\n",
        "    # try:\n",
        "    #   model = func_timeout(1350, defense_method, args=(model, val_dataset,1350))\n",
        "    # except FunctionTimedOut:\n",
        "\t  #   print ( \"This test case exceed the maximum executable time!\\n\")\n",
        "    # models.append(model)\n",
        "\n",
        "    ## Test CIFAR-10 SIG \n",
        "    print(\"----------------- Testing defense: CIFAR-10 SIG -----------------\")\n",
        "    val_dataset, _, _, _, model = CIFAR10_SIG()\n",
        "    try:\n",
        "      model = func_timeout(900, defense_method, args=(model, val_dataset,900))\n",
        "    except FunctionTimedOut:\n",
        "\t    print ( \"This test case exceed the maximum executable time!\\n\")\n",
        "    models.append(model)\n",
        "\n",
        "    ## Test Tiny-Imagenet Narcissus \n",
        "    print(\"----------------- Testing defense: Tiny-Imagenet Narcissus -----------------\")\n",
        "    val_dataset, _, _, _, model = TinyImangeNet_Narcissus()\n",
        "    try:\n",
        "      model = func_timeout(1800, defense_method, args=(model, val_dataset,1800))\n",
        "    except FunctionTimedOut:\n",
        "\t    print ( \"This test case exceed the maximum executable time!\\n\")\n",
        "    models.append(model)\n",
        "\n",
        "    ## Test GTSRB WaNet & Smooth \n",
        "    print(\"----------------- Testing defense: GTSRB WaNet & Smooth -----------------\")\n",
        "    val_dataset, _, _, _, model = GTSRB_WaNetFrequency()\n",
        "    try:\n",
        "      model = func_timeout(690, defense_method, args=(model, val_dataset,690))\n",
        "    except FunctionTimedOut:\n",
        "\t    print ( \"This test case exceed the maximum executable time!\\n\")\n",
        "    models.append(model)\n",
        "\n",
        "    ## Test STL-10 \n",
        "    print(\"----------------- Testing defense: STL-10 -----------------\")\n",
        "    val_dataset, _, _, _, model = STL10_Clean()\n",
        "    try:\n",
        "      model = func_timeout(450, defense_method, args=(model, val_dataset,450))\n",
        "    except FunctionTimedOut:\n",
        "\t    print ( \"This test case exceed the maximum executable time!\\n\")\n",
        "    models.append(model)\n",
        "    return models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2A4BC_518Cdg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title I-BAU Defense\n",
        "def IBAU(net, val_dataset, allow_time):\n",
        "    '''Code from https://github.com/YiZeng623/I-BAU'''\n",
        "    allow_time = allow_time*1000\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, num_workers=4,  shuffle=True)\n",
        "\n",
        "    images_list, labels_list = [], []\n",
        "    for index, (images, labels) in enumerate(val_dataloader):\n",
        "        images_list.append(images)\n",
        "        labels_list.append(labels)\n",
        "\n",
        "    def loss_inner(perturb, model_params):\n",
        "        images = images_list[0].to(device)\n",
        "        labels = labels_list[0].long().to(device)\n",
        "        per_img = images+perturb[0]\n",
        "        per_logits = net.forward(per_img)\n",
        "        loss = F.cross_entropy(per_logits, labels, reduction='none')\n",
        "        loss_regu = torch.mean(-loss) +0.001*torch.pow(torch.norm(perturb[0]),2)\n",
        "        return loss_regu\n",
        "\n",
        "    def loss_outer(perturb, model_params):\n",
        "        random_pick = np.where(np.random.uniform(0,1,32)>0.97)[0].shape[0]\n",
        "        \n",
        "        images, labels = images_list[batchnum].to(device), labels_list[batchnum].long().to(device)\n",
        "        patching = torch.zeros_like(images, device='cuda')\n",
        "        number = images.shape[0]\n",
        "        random_pick = min(number, random_pick)\n",
        "        rand_idx = random.sample(list(np.arange(number)),random_pick)\n",
        "        patching[rand_idx] = perturb[0]\n",
        "        unlearn_imgs = images+patching\n",
        "        logits = net(unlearn_imgs)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(logits, labels)\n",
        "        return loss\n",
        "    \n",
        "    def get_lr(net, loader):\n",
        "        lr_list = [0.1**i for i in range(2,8)]\n",
        "        acc_list = []\n",
        "        for i in range(len(lr_list)):\n",
        "            copy_net = copy.deepcopy(net)\n",
        "            copy_net = copy_net.cuda()\n",
        "            optimizer = torch.optim.Adam(copy_net.parameters(), lr=lr_list[i])\n",
        "            for _, data in enumerate(loader, 0):\n",
        "                length = len(loader)\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.type(torch.LongTensor).to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward\n",
        "                outputs = copy_net(inputs)\n",
        "                loss = F.cross_entropy(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            acc_list.append(get_results(copy_net, loader.dataset))\n",
        "            print(\"lr = \" + str(lr_list[i]) + \" ACC: \" + str(acc_list[-1]*100))\n",
        "        return 0.1**(acc_list.index(max(acc_list))+2)\n",
        "\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    \n",
        "    #contral the time\n",
        "    every_time = []\n",
        "    for _ in range(5):\n",
        "        every_time.append(0)\n",
        "    \n",
        "    start.record()\n",
        "    \n",
        "    curr_lr = get_lr(net, val_dataloader)\n",
        "    net = net.cuda()\n",
        "    outer_opt = torch.optim.Adam(net.parameters(), lr=curr_lr)\n",
        "    inner_opt = GradientDescent(loss_inner, 0.1)\n",
        "    \n",
        "    end.record()\n",
        "    torch.cuda.synchronize()\n",
        "    every_time.append(start.elapsed_time(end))\n",
        "\n",
        "    net.train()\n",
        "    while (allow_time - np.sum(every_time)) > (np.mean(every_time[-5:])*2) and len(every_time) < 155:\n",
        "        start.record()\n",
        "        batch_pert = torch.zeros_like(val_dataset[0][0].unsqueeze(0), requires_grad=True, device='cuda')\n",
        "        batch_lr = 0.0005*val_dataset[0][0].shape[1]-0.0155\n",
        "        batch_opt = torch.optim.Adam(params=[batch_pert],lr=batch_lr)\n",
        "\n",
        "        for index, (images, labels) in enumerate(val_dataloader):\n",
        "            images = images.to(device)\n",
        "            ori_lab = torch.argmax(net.forward(images),axis = 1).long()\n",
        "            per_logits = net.forward(images+batch_pert)\n",
        "            loss = -F.cross_entropy(per_logits, ori_lab) + 0.001*torch.pow(torch.norm(batch_pert),2)\n",
        "            batch_opt.zero_grad()\n",
        "            loss.backward(retain_graph = True)\n",
        "#             if index % 4 == 0:\n",
        "            batch_opt.step()\n",
        "            \n",
        "\n",
        "        #unlearn step         \n",
        "        for batchnum in range(len(images_list)):\n",
        "            outer_opt.zero_grad()\n",
        "            fixed_point(batch_pert, list(net.parameters()), 5, inner_opt, loss_outer) \n",
        "#             if batchnum % 4 == 0:\n",
        "            outer_opt.step()\n",
        "            \n",
        "\n",
        "        print('Round:',len(every_time)-5)\n",
        "        end.record()\n",
        "        torch.cuda.synchronize()\n",
        "        every_time.append(start.elapsed_time(end))\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jmy3w60L8Cdh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Neural Cleanse Defense\n",
        "def neural_cleanse(model, val_dataset, allow_time):\n",
        "    '''Code from https://github.com/VinAIResearch/input-aware-backdoor-attack-release'''\n",
        "    class RegressionModel(nn.Module):\n",
        "        def __init__(self, opt, init_mask, init_pattern, model):\n",
        "            self._EPSILON = opt.EPSILON\n",
        "            super(RegressionModel, self).__init__()\n",
        "            self.mask_tanh = nn.Parameter(torch.tensor(init_mask))\n",
        "            self.pattern_tanh = nn.Parameter(torch.tensor(init_pattern))\n",
        "\n",
        "            self.classifier = copy.deepcopy(model)\n",
        "            for param in self.classifier.parameters():\n",
        "                param.requires_grad = False\n",
        "            self.classifier.eval()\n",
        "            self.classifier = self.classifier.cuda()\n",
        "\n",
        "        def forward(self, x):\n",
        "            mask = self.get_raw_mask()\n",
        "            pattern = self.get_raw_pattern()\n",
        "            x = (1 - mask) * x + mask * pattern\n",
        "            return self.classifier(x)\n",
        "\n",
        "        def get_raw_mask(self):\n",
        "            mask = nn.Tanh()(self.mask_tanh)\n",
        "            return mask / (2 + self._EPSILON) + 0.5\n",
        "\n",
        "        def get_raw_pattern(self):\n",
        "            pattern = nn.Tanh()(self.pattern_tanh)\n",
        "            return pattern / (2 + self._EPSILON) + 0.5\n",
        "\n",
        "    class Recorder:\n",
        "        def __init__(self, opt):\n",
        "            super().__init__()\n",
        "\n",
        "            # Best optimization results\n",
        "            self.mask_best = None\n",
        "            self.pattern_best = None\n",
        "            self.reg_best = float(\"inf\")\n",
        "\n",
        "            # Logs and counters for adjusting balance cost\n",
        "            self.logs = []\n",
        "            self.cost_set_counter = 0\n",
        "            self.cost_up_counter = 0\n",
        "            self.cost_down_counter = 0\n",
        "            self.cost_up_flag = False\n",
        "            self.cost_down_flag = False\n",
        "\n",
        "            # Counter for early stop\n",
        "            self.early_stop_counter = 0\n",
        "            self.early_stop_reg_best = self.reg_best\n",
        "\n",
        "            # Cost\n",
        "            self.cost = opt.init_cost\n",
        "            self.cost_multiplier_up = opt.cost_multiplier\n",
        "            self.cost_multiplier_down = opt.cost_multiplier ** 1.5\n",
        "\n",
        "        def reset_state(self, opt):\n",
        "            self.cost = opt.init_cost\n",
        "            self.cost_up_counter = 0\n",
        "            self.cost_down_counter = 0\n",
        "            self.cost_up_flag = False\n",
        "            self.cost_down_flag = False\n",
        "            print(\"Initialize cost to {:f}\".format(self.cost))\n",
        "\n",
        "    def train(opt, init_mask, init_pattern, model, val_dataset):\n",
        "\n",
        "        test_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=128, num_workers=4, shuffle=False)\n",
        "\n",
        "        # Build regression model\n",
        "        regression_model = RegressionModel(opt, init_mask, init_pattern, model).cuda()\n",
        "\n",
        "        # Set optimizer\n",
        "        optimizerR = torch.optim.Adam(regression_model.parameters(), lr=opt.lr, betas=(0.5, 0.9))\n",
        "\n",
        "        # Set recorder (for recording best result)\n",
        "        recorder = Recorder(opt)\n",
        "\n",
        "        for epoch in range(opt.epoch):\n",
        "            early_stop = train_step(regression_model, optimizerR, test_dataloader, recorder, epoch, opt)\n",
        "            if early_stop:\n",
        "                break\n",
        "\n",
        "        return recorder, opt\n",
        "\n",
        "\n",
        "    def train_step(regression_model, optimizerR, dataloader, recorder, epoch, opt):\n",
        "        print(\"Epoch {} - Label: {}:\".format(epoch, opt.target_label))\n",
        "        # Set losses\n",
        "        cross_entropy = nn.CrossEntropyLoss()\n",
        "        total_pred = 0\n",
        "        true_pred = 0\n",
        "\n",
        "        # Record loss for all mini-batches\n",
        "        loss_ce_list = []\n",
        "        loss_reg_list = []\n",
        "        loss_list = []\n",
        "        loss_acc_list = []\n",
        "\n",
        "        # Set inner early stop flag\n",
        "        inner_early_stop_flag = False\n",
        "        for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
        "            # Forwarding and update model\n",
        "            optimizerR.zero_grad()\n",
        "\n",
        "            inputs = inputs.cuda()\n",
        "            sample_num = inputs.shape[0]\n",
        "            total_pred += sample_num\n",
        "            target_labels = torch.ones((sample_num), dtype=torch.int64).cuda() * opt.target_label\n",
        "            predictions = regression_model(inputs)\n",
        "\n",
        "            loss_ce = cross_entropy(predictions, target_labels)\n",
        "            loss_reg = torch.norm(regression_model.get_raw_mask(), 2)\n",
        "            total_loss = loss_ce + recorder.cost * loss_reg\n",
        "            total_loss.backward()\n",
        "            optimizerR.step()\n",
        "\n",
        "            # Record minibatch information to list\n",
        "            minibatch_accuracy = torch.sum(torch.argmax(predictions, dim=1) == target_labels).detach() * 100.0 / sample_num\n",
        "            loss_ce_list.append(loss_ce.detach())\n",
        "            loss_reg_list.append(loss_reg.detach())\n",
        "            loss_list.append(total_loss.detach())\n",
        "            loss_acc_list.append(minibatch_accuracy)\n",
        "\n",
        "            true_pred += torch.sum(torch.argmax(predictions, dim=1) == target_labels).detach()\n",
        "\n",
        "        loss_ce_list = torch.stack(loss_ce_list)\n",
        "        loss_reg_list = torch.stack(loss_reg_list)\n",
        "        loss_list = torch.stack(loss_list)\n",
        "        loss_acc_list = torch.stack(loss_acc_list)\n",
        "\n",
        "        avg_loss_ce = torch.mean(loss_ce_list)\n",
        "        avg_loss_reg = torch.mean(loss_reg_list)\n",
        "        avg_loss_acc = torch.mean(loss_acc_list)\n",
        "\n",
        "        # Check to save best mask or not\n",
        "        if avg_loss_acc >= opt.atk_succ_threshold and avg_loss_reg < recorder.reg_best:\n",
        "            recorder.mask_best = regression_model.get_raw_mask().detach()\n",
        "            recorder.pattern_best = regression_model.get_raw_pattern().detach()\n",
        "            recorder.reg_best = avg_loss_reg\n",
        "            print(\" Updated !!!\")\n",
        "\n",
        "        # Show information\n",
        "        print(\n",
        "            \"  Result: Accuracy: {:.3f} | Cross Entropy Loss: {:.6f} | Reg Loss: {:.6f} | Reg best: {:.6f}\".format(\n",
        "                true_pred * 100.0 / total_pred, avg_loss_ce, avg_loss_reg, recorder.reg_best\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Check early stop\n",
        "        if opt.early_stop:\n",
        "            if recorder.reg_best < float(\"inf\"):\n",
        "                if recorder.reg_best >= opt.early_stop_threshold * recorder.early_stop_reg_best:\n",
        "                    recorder.early_stop_counter += 1\n",
        "                else:\n",
        "                    recorder.early_stop_counter = 0\n",
        "\n",
        "            recorder.early_stop_reg_best = min(recorder.early_stop_reg_best, recorder.reg_best)\n",
        "\n",
        "            if (\n",
        "                recorder.cost_down_flag\n",
        "                and recorder.cost_up_flag\n",
        "                and recorder.early_stop_counter >= opt.early_stop_patience\n",
        "            ):\n",
        "                print(\"Early_stop !!!\")\n",
        "                inner_early_stop_flag = True\n",
        "\n",
        "        if not inner_early_stop_flag:\n",
        "            # Check cost modification\n",
        "            if recorder.cost == 0 and avg_loss_acc >= opt.atk_succ_threshold:\n",
        "                recorder.cost_set_counter += 1\n",
        "                if recorder.cost_set_counter >= opt.patience:\n",
        "                    recorder.reset_state(opt)\n",
        "            else:\n",
        "                recorder.cost_set_counter = 0\n",
        "\n",
        "            if avg_loss_acc >= opt.atk_succ_threshold:\n",
        "                recorder.cost_up_counter += 1\n",
        "                recorder.cost_down_counter = 0\n",
        "            else:\n",
        "                recorder.cost_up_counter = 0\n",
        "                recorder.cost_down_counter += 1\n",
        "\n",
        "            if recorder.cost_up_counter >= opt.patience:\n",
        "                recorder.cost_up_counter = 0\n",
        "                print(\"Up cost from {} to {}\".format(recorder.cost, recorder.cost * recorder.cost_multiplier_up))\n",
        "                recorder.cost *= recorder.cost_multiplier_up\n",
        "                recorder.cost_up_flag = True\n",
        "\n",
        "            elif recorder.cost_down_counter >= opt.patience:\n",
        "                recorder.cost_down_counter = 0\n",
        "                print(\"Down cost from {} to {}\".format(recorder.cost, recorder.cost / recorder.cost_multiplier_down))\n",
        "                recorder.cost /= recorder.cost_multiplier_down\n",
        "                recorder.cost_down_flag = True\n",
        "\n",
        "            # Save the final version\n",
        "            if recorder.mask_best is None:\n",
        "                recorder.mask_best = regression_model.get_raw_mask().detach()\n",
        "                recorder.pattern_best = regression_model.get_raw_pattern().detach()\n",
        "\n",
        "        return inner_early_stop_flag\n",
        "\n",
        "    class opt:\n",
        "        total_label = np.unique(val_dataset.targets).shape[0]\n",
        "        input_height,input_width,input_channel = val_dataset[0][0].shape[1],val_dataset[0][0].shape[2],val_dataset[0][0].shape[0]\n",
        "        EPSILON = 1e-7\n",
        "        lr = 1e-1\n",
        "        init_cost = 1e-3\n",
        "        cost_multiplier = 2.0\n",
        "        epoch = 1\n",
        "        atk_succ_threshold = 99.0\n",
        "        early_stop_threshold = 99.0\n",
        "        early_stop = True\n",
        "        patience = 5\n",
        "    opt = opt()\n",
        "\n",
        "    init_mask = np.ones((1, opt.input_height, opt.input_width)).astype(np.float32)\n",
        "    init_pattern = np.ones((opt.input_channel, opt.input_height, opt.input_width)).astype(np.float32)\n",
        "\n",
        "    masks = []\n",
        "    patterns = []\n",
        "    idx_mapping = {}\n",
        "\n",
        "    for target_label in range(opt.total_label):\n",
        "        print(\"----------------- Analyzing label: {} -----------------\".format(target_label))\n",
        "        opt.target_label = target_label\n",
        "        recorder, opt = train(opt, init_mask, init_pattern, model, val_dataset)\n",
        "\n",
        "        mask = recorder.mask_best\n",
        "        masks.append(mask)\n",
        "        pattern = recorder.pattern_best\n",
        "        patterns.append(pattern)\n",
        "\n",
        "        idx_mapping[target_label] = len(masks) - 1\n",
        "\n",
        "    l1_norm_list = torch.stack([torch.sum(torch.abs(m)) for m in masks])\n",
        "    print(\"{} labels found\".format(len(l1_norm_list)))\n",
        "    print(\"Norm values: {}\".format(l1_norm_list))\n",
        "\n",
        "    def outlier_detection(l1_norm_list, idx_mapping, opt):\n",
        "        print(\"-\" * 30)\n",
        "        print(\"Determining whether model is backdoor\")\n",
        "        consistency_constant = 1.4826\n",
        "        median = torch.median(l1_norm_list)\n",
        "        mad = consistency_constant * torch.median(torch.abs(l1_norm_list - median))\n",
        "        min_mad = torch.abs(torch.min(l1_norm_list) - median) / mad\n",
        "\n",
        "        print(\"Median: {}, MAD: {}\".format(median, mad))\n",
        "        print(\"Anomaly index: {}\".format(min_mad))\n",
        "\n",
        "        if min_mad < 2:\n",
        "            print(\"Not a backdoor model\")\n",
        "        else:\n",
        "            print(\"This is a backdoor model\")\n",
        "\n",
        "        flag_list = []\n",
        "        for y_label in idx_mapping:\n",
        "            if l1_norm_list[idx_mapping[y_label]] > median:\n",
        "                continue\n",
        "            if torch.abs(l1_norm_list[idx_mapping[y_label]] - median) / mad > 2:\n",
        "                flag_list.append((y_label, l1_norm_list[idx_mapping[y_label]]))\n",
        "\n",
        "        if len(flag_list) > 0:\n",
        "            flag_list = sorted(flag_list, key=lambda x: x[1])\n",
        "\n",
        "        print(\n",
        "            \"Flagged label list: {}\".format(\",\".join([\"{}: {}\".format(y_label, l_norm) for y_label, l_norm in flag_list]))\n",
        "        )\n",
        "\n",
        "        return [y_label for y_label, _ in flag_list]\n",
        "\n",
        "    poi_label_list = outlier_detection(l1_norm_list, idx_mapping, opt)\n",
        "\n",
        "    if len(poi_label_list) == 0:\n",
        "        return model\n",
        "\n",
        "    class unlearning_ds(Dataset):\n",
        "        def __init__(self, dataset, mask, trigger, patch_ratio):\n",
        "            self.dataset = dataset\n",
        "            self.patch_list = random.sample(list(np.arange(len(dataset))),int(len(dataset)*patch_ratio))\n",
        "            self.mask = mask\n",
        "            self.trigger = trigger\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            image = self.dataset[idx][0]\n",
        "            label = self.dataset[idx][1]\n",
        "            if idx in self.patch_list:\n",
        "                image = (image + self.mask * (self.trigger - image))\n",
        "            image = torch.clamp(image,-1,1)\n",
        "            return (image, label)\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.dataset)\n",
        "\n",
        "    for i in poi_label_list:\n",
        "        curr_masks = masks[i].cpu()\n",
        "        curr_pattern = patterns[i].cpu()\n",
        "        ul_set = unlearning_ds(val_dataset, curr_masks, curr_pattern, 0.2)\n",
        "        ul_loader =  torch.utils.data.DataLoader(ul_set, batch_size=128, num_workers=4, shuffle=True)\n",
        "\n",
        "        model.train()\n",
        "        outer_opt = torch.optim.SGD(params=model.parameters(), lr = 8e-2)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        for _ in range(10):\n",
        "            train_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            acc_rec = 0\n",
        "            for batch_idx, (inputs, targets) in enumerate(ul_loader):\n",
        "                inputs, targets = inputs.cuda(), targets.type(torch.LongTensor).cuda()\n",
        "                outer_opt.zero_grad()\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                loss.backward()\n",
        "                outer_opt.step()        \n",
        "\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += targets.size(0)\n",
        "                correct += predicted.eq(targets).sum().item()\n",
        "            print('Unlearn Acc: %.3f%% (%d/%d)'\n",
        "                                % (100.*correct/total, correct, total))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFxsTR3E8Cdj"
      },
      "source": [
        "# 4. Implement your defense method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "8KQKqgGs8Cdj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title MYOWN Defense\n",
        "def MYOWN(net, val_dataset, allow_time):\n",
        "    allow_time = allow_time*1000\n",
        "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=48, num_workers=6,  shuffle=True)\n",
        "    # val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, num_workers=4,  shuffle=True)\n",
        "\n",
        "    images_list, labels_list = [], []\n",
        "    for index, (images, labels) in enumerate(val_dataloader):\n",
        "        images_list.append(images)\n",
        "        labels_list.append(labels)\n",
        "\n",
        "    def loss_inner(perturb, model_params):\n",
        "        images = images_list[0].to(device)\n",
        "        labels = labels_list[0].long().to(device)\n",
        "        per_img = images+perturb[0]\n",
        "        per_logits = net.forward(per_img)\n",
        "        loss = F.cross_entropy(per_logits, labels, reduction='none')\n",
        "        loss_regu = torch.mean(-loss) +0.001*torch.pow(torch.norm(perturb[0]),2)\n",
        "        return loss_regu\n",
        "\n",
        "    def loss_outer(perturb, model_params):\n",
        "        random_pick = np.where(np.random.uniform(0,1,32)>0.97)[0].shape[0]\n",
        "        \n",
        "        images, labels = images_list[batchnum].to(device), labels_list[batchnum].long().to(device)\n",
        "        patching = torch.zeros_like(images, device='cuda')\n",
        "        number = images.shape[0]\n",
        "        random_pick = min(number, random_pick)\n",
        "        rand_idx = random.sample(list(np.arange(number)),random_pick)\n",
        "        patching[rand_idx] = perturb[0]\n",
        "        unlearn_imgs = images+patching\n",
        "        logits = net(unlearn_imgs)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        loss = criterion(logits, labels)\n",
        "        return loss\n",
        "    \n",
        "    def get_lr(net, loader):\n",
        "        lr_list = [0.1**i for i in range(2,8)]\n",
        "        acc_list = []\n",
        "        for i in range(len(lr_list)):\n",
        "            copy_net = copy.deepcopy(net)\n",
        "            copy_net = copy_net.cuda()\n",
        "            optimizer = torch.optim.Adam(copy_net.parameters(), lr=lr_list[i])\n",
        "            for _, data in enumerate(loader, 0):\n",
        "                length = len(loader)\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.type(torch.LongTensor).to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward\n",
        "                outputs = copy_net(inputs)\n",
        "                loss = F.cross_entropy(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            acc_list.append(get_results(copy_net, loader.dataset))\n",
        "            print(\"lr = \" + str(lr_list[i]) + \" ACC: \" + str(acc_list[-1]*100))\n",
        "        return 0.1**(acc_list.index(max(acc_list))+2)\n",
        "\n",
        "    start = torch.cuda.Event(enable_timing=True)\n",
        "    end = torch.cuda.Event(enable_timing=True)\n",
        "    \n",
        "    #contral the time\n",
        "    every_time = []\n",
        "    for _ in range(5):\n",
        "        every_time.append(0)\n",
        "    \n",
        "    start.record()\n",
        "    \n",
        "    curr_lr = get_lr(net, val_dataloader)\n",
        "    net = net.cuda()\n",
        "    outer_opt = torch.optim.Adam(net.parameters(), lr=curr_lr)\n",
        "    inner_opt = GradientDescent(loss_inner, 0.1)\n",
        "    \n",
        "    end.record()\n",
        "    torch.cuda.synchronize()\n",
        "    every_time.append(start.elapsed_time(end))\n",
        "\n",
        "    net.train()\n",
        "    while (allow_time - np.sum(every_time)) > (np.mean(every_time[-5:])*2) and len(every_time) < 155:\n",
        "        start.record()\n",
        "        batch_pert = torch.zeros_like(val_dataset[0][0].unsqueeze(0), requires_grad=True, device='cuda')\n",
        "        batch_lr = 0.0005*val_dataset[0][0].shape[1]-0.0155\n",
        "        batch_opt = torch.optim.Adam(params=[batch_pert],lr=batch_lr)\n",
        "\n",
        "        for index, (images, labels) in enumerate(val_dataloader):\n",
        "            images = images.to(device)\n",
        "            ori_lab = torch.argmax(net.forward(images),axis = 1).long()\n",
        "            per_logits = net.forward(images+batch_pert)\n",
        "            loss = -F.cross_entropy(per_logits, ori_lab) + 0.001*torch.pow(torch.norm(batch_pert),2)\n",
        "            batch_opt.zero_grad()\n",
        "            loss.backward(retain_graph = True)\n",
        "#             if index % 4 == 0:\n",
        "            batch_opt.step()\n",
        "            \n",
        "\n",
        "        #unlearn step         \n",
        "        for batchnum in range(len(images_list)):\n",
        "            outer_opt.zero_grad()\n",
        "            fixed_point(batch_pert, list(net.parameters()), 5, inner_opt, loss_outer) \n",
        "#             if batchnum % 4 == 0:\n",
        "            outer_opt.step()\n",
        "            \n",
        "\n",
        "        print('Round:',len(every_time)-5)\n",
        "        end.record()\n",
        "        torch.cuda.synchronize()\n",
        "        every_time.append(start.elapsed_time(end))\n",
        "    return net"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Test defense"
      ],
      "metadata": {
        "id": "THKu7ewXHYGi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "w6fo4MlW8Cdj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b0cdf57-06d1-4c8c-93a3-3dd9ace9cb7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Testing defense: CIFAR-10 SIG -----------------\n",
            "lr = 0.010000000000000002 ACC: 14.099999999999998\n",
            "lr = 0.0010000000000000002 ACC: 92.60000000000001\n",
            "lr = 0.00010000000000000002 ACC: 95.8\n",
            "lr = 1.0000000000000003e-05 ACC: 91.5\n",
            "lr = 1.0000000000000004e-06 ACC: 91.3\n",
            "lr = 1.0000000000000004e-07 ACC: 91.60000000000001\n",
            "Round: 1\n",
            "Round: 2\n",
            "Round: 3\n",
            "Round: 4\n",
            "Round: 5\n",
            "Round: 6\n",
            "Round: 7\n",
            "Round: 8\n",
            "Round: 9\n",
            "Round: 10\n",
            "Round: 11\n",
            "Round: 12\n",
            "Round: 13\n",
            "Round: 14\n",
            "Round: 15\n",
            "Round: 16\n",
            "Round: 17\n",
            "Round: 18\n",
            "Round: 19\n",
            "Round: 20\n",
            "Round: 21\n",
            "Round: 22\n",
            "Round: 23\n",
            "Round: 24\n",
            "Round: 25\n",
            "Round: 26\n",
            "Round: 27\n",
            "Round: 28\n",
            "Round: 29\n",
            "Round: 30\n",
            "Round: 31\n",
            "Round: 32\n",
            "Round: 33\n",
            "Round: 34\n",
            "Round: 35\n",
            "Round: 36\n",
            "Round: 37\n",
            "Round: 38\n",
            "Round: 39\n",
            "Round: 40\n",
            "Round: 41\n",
            "Round: 42\n",
            "Round: 43\n",
            "Round: 44\n",
            "Round: 45\n",
            "Round: 46\n",
            "Round: 47\n",
            "Round: 48\n",
            "Round: 49\n",
            "Round: 50\n",
            "Round: 51\n",
            "Round: 52\n",
            "Round: 53\n",
            "----------------- Testing defense: Tiny-Imagenet Narcissus -----------------\n",
            "lr = 0.010000000000000002 ACC: 0.6\n",
            "lr = 0.0010000000000000002 ACC: 74.6\n",
            "lr = 0.00010000000000000002 ACC: 70.89999999999999\n",
            "lr = 1.0000000000000003e-05 ACC: 54.949999999999996\n",
            "lr = 1.0000000000000004e-06 ACC: 53.25\n",
            "lr = 1.0000000000000004e-07 ACC: 53.300000000000004\n",
            "Round: 1\n",
            "Round: 2\n",
            "Round: 3\n",
            "Round: 4\n",
            "Round: 5\n",
            "Round: 6\n",
            "Round: 7\n",
            "Round: 8\n",
            "Round: 9\n",
            "Round: 10\n",
            "Round: 11\n",
            "Round: 12\n",
            "Round: 13\n",
            "Round: 14\n",
            "----------------- Testing defense: GTSRB WaNet & Smooth -----------------\n",
            "lr = 0.010000000000000002 ACC: 6.447368421052632\n",
            "lr = 0.0010000000000000002 ACC: 28.55263157894737\n",
            "lr = 0.00010000000000000002 ACC: 99.21052631578947\n",
            "lr = 1.0000000000000003e-05 ACC: 94.86842105263158\n",
            "lr = 1.0000000000000004e-06 ACC: 92.5\n",
            "lr = 1.0000000000000004e-07 ACC: 93.42105263157895\n",
            "Round: 1\n",
            "Round: 2\n",
            "Round: 3\n",
            "Round: 4\n",
            "Round: 5\n",
            "Round: 6\n",
            "Round: 7\n",
            "Round: 8\n",
            "Round: 9\n",
            "Round: 10\n",
            "Round: 11\n",
            "Round: 12\n",
            "----------------- Testing defense: STL-10 -----------------\n",
            "lr = 0.010000000000000002 ACC: 83.0\n",
            "lr = 0.0010000000000000002 ACC: 100.0\n",
            "lr = 0.00010000000000000002 ACC: 100.0\n",
            "lr = 1.0000000000000003e-05 ACC: 100.0\n",
            "lr = 1.0000000000000004e-06 ACC: 100.0\n",
            "lr = 1.0000000000000004e-07 ACC: 100.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a25b5b93e1d8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the defended model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_defense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIBAU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Test all attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## Test Pubfig all2all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-2f9afa4d3397>\u001b[0m in \u001b[0;36mtest_defense\u001b[0;34m(defense_method)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTL10_Clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m450\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefense_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m450\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFunctionTimedOut\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m\"This test case exceed the maximum executable time!\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/func_timeout/dafunc.py\u001b[0m in \u001b[0;36mfunc_timeout\u001b[0;34m(timeout, func, args, kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mraise_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/func_timeout/py3_raise.py\u001b[0m in \u001b[0;36mraise_exception\u001b[0;34m(exception)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Only available in python3.3+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-83ca37ba264b>\u001b[0m in \u001b[0;36mIBAU\u001b[0;34m(net, val_dataset, allow_time)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatchnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mouter_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mfixed_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_pert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_outer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;31m#             if batchnum % 4 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mouter_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/util.py\u001b[0m in \u001b[0;36mfixed_point\u001b[0;34m(params, hparams, K, fp_map, outer_loss, tol, set_grad, stochastic)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         \u001b[0mw_mapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, params, hparams, create_graph)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/util.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, params, hparams, create_graph)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_size_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgd_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/util.py\u001b[0m in \u001b[0;36mgd_step\u001b[0;34m(params, loss, step_size, create_graph)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgd_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_vmap_internals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_none_pass_through\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 40.81 MiB free; 13.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# Get the defended model\n",
        "models = test_defense(IBAU)\n",
        "\n",
        "# Test all attack\n",
        "## Test Pubfig all2all\n",
        "# print(\"----------------- Testing defense result: PubFig all2all -----------------\")\n",
        "# _, test_dataset, asr_dataset, pacc_dataset, _ = PubFig_all2all()\n",
        "# model = models[0]\n",
        "# print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
        "# print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
        "# print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
        "\n",
        "## Test CIFAR-10 SIG \n",
        "print(\"----------------- Testing defense result: CIFAR-10 SIG -----------------\")\n",
        "_, test_dataset, asr_dataset, pacc_dataset, _ = CIFAR10_SIG()\n",
        "model = models[1]\n",
        "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
        "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
        "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
        "\n",
        "## Test Tiny-Imagenet Narcissus \n",
        "print(\"----------------- Testing defense result: Tiny-Imagenet Narcissus -----------------\")\n",
        "_, test_dataset, asr_dataset, pacc_dataset, _ = TinyImangeNet_Narcissus()\n",
        "model = models[2]\n",
        "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
        "print('ASR %.3f%%' % (100 * get_results(model, asr_dataset)))\n",
        "print('PACC %.3f%%' % (100 * get_results(model, pacc_dataset)))\n",
        "\n",
        "## Test GTSRB WaNet & Smooth \n",
        "print(\"----------------- Testing defense result: GTSRB WaNet & Smooth -----------------\")\n",
        "_, test_dataset, asr_dataset, pacc_dataset, _ = GTSRB_WaNetFrequency()\n",
        "model = models[3]\n",
        "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))\n",
        "print('WaNet ASR %.3f%%' % (100 * get_results(model, asr_dataset[0])))\n",
        "print('WaNet PACC %.3f%%' % (100 * get_results(model, pacc_dataset[0])))\n",
        "print('Smooth ASR %.3f%%' % (100 * get_results(model, asr_dataset[1])))\n",
        "print('Smooth PACC %.3f%%' % (100 * get_results(model, pacc_dataset[1])))\n",
        "\n",
        "## Test STL-10 \n",
        "print(\"----------------- Testing defense result: STL-10 -----------------\")\n",
        "_, test_dataset, _, _, _ = STL10_Clean()\n",
        "model = models[4]\n",
        "print('ACC：%.3f%%' % (100 * get_results(model, test_dataset)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7b8be34f2a64f133f414bd034f75b72cc1c8d29070f6944ffe8bd65ff6cd5b9f"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}